{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "Use data from [ERA5-Land](https://www.ecmwf.int/en/era5-land) to examine time scales of variability in surface variables at the grid point closest to HU Beltsville.\n",
    "\n",
    "We demonstrate some of the capabilities of [xarray](http://xarray.pydata.org/en/stable/) and other scientific Python packages.\n",
    "\n",
    "This tutorial notebook is part of [zmoon92/hu-pbl-workshop-2020/tree/master/python-tutorial](https://github.com/zmoon92/hu-pbl-workshop-2020/tree/master/python-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from ipywidgets import interact, Dropdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pvlib\n",
    "from scipy.fftpack import rfft, irfft\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.autolayout\": True,\n",
    "    \"axes.xmargin\": 0,\n",
    "})\n",
    "\n",
    "# define some defaults\n",
    "xrp = {\n",
    "    \"size\": 5.2,  # height; if we pass it to xarray plot methods, it will create a new fig\n",
    "    \"aspect\": 1.6,  # aspect * size = width\n",
    "}\n",
    "figsize = (xrp[\"size\"]*xrp[\"aspect\"], xrp[\"size\"])  # width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre\n",
    "\n",
    "### Load the data\n",
    "\n",
    "According to [the GRUAN page](https://www.gruan.org/network/sites/beltsville), we want to find the point closest to 39.0542 Â°N, 76.8775 Â°W. In ERA5-Land, which has a resolution of 0.1Â°, this turns out to be the point (39.1, -76.9). I have already extracted a few years of data for that point to the file `era5-land_bel.nc`. This file is available if you are running the notebook on the MyBinder for the repo (or have cloned the repo). Otherwise, you will need to download it if you want to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load and examine the data set.\n",
    "\n",
    "In the notebook, you can interact with the data set's fancy HTML representation, which will show up if you have xarray [v0.15.1+](http://xarray.pydata.org/en/stable/whats-new.html#v0-15-1-23-mar-2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"era5-land_bel.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.t2m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.u10.plot.line(**xrp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how xarray does all of the labeling for us, including units and descriptive name for the variable being plotted. This is possible because the data set we have loaded follows the [CF Conventions](https://cfconventions.org/), specifying `units` and `long_name` attributes for each variable.\n",
    "\n",
    "See the [xarray guide to plotting page](http://xarray.pydata.org/en/stable/plotting.html) for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [`.rolling` method](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.rolling.html) of a data array, we can easily plot moving averages. Here we select the variable `t2m`, the 2-m temperature. See the [xarray indexing/selecting guide page](http://xarray.pydata.org/en/stable/indexing.html) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.t2m.plot.line(**xrp, lw=0.5, alpha=0.3, label=\"original hourly data\")\n",
    "ax = plt.gca(); ylabel = ax.get_ylabel()  # save the auto-added label\n",
    "\n",
    "# Add some moving averages (the time resolution is 1 hour)\n",
    "ds.t2m.rolling(time=24, center=True).mean().plot(lw=1.0, alpha=0.5, label=\"1 day moving average\")\n",
    "ds.t2m.rolling(time=24*30, center=True).mean().plot(lw=1.2, alpha=0.8, label=\"30 day moving average\")\n",
    "ds.t2m.rolling(time=24*90, center=True).mean().plot(lw=1.8, alpha=1.0, label=\"90 day moving average\")\n",
    "ax.set_ylabel(ylabel)  # put the label back\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘† It appears that the near-surface temperature data we have could use some quality control: there are quite a few times when temperature spikes to ~310 K during the winter! But we won't worry about that now...\n",
    "\n",
    "We see that adding more points to our moving average makes the seasonal cycle and interannual variability more clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a relationship between the sensible heat flux and near-surface air temperature? Let's make a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds.plot.scatter(x=\"sshf\", y=\"t2m\", marker=\".\", alpha=0.3, edgecolors=\"none\", **xrp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't appear to be much of a relationship. How about if we subset the data to only include midday in the summer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = ds.time.dt.hour\n",
    "mo = ds.time.dt.month\n",
    "ds.where(\n",
    "    (h >= 15) & (h <= 19) & (mo >= 6) & (mo <= 8)  # during the summer, we are UTC-4\n",
    ").plot.scatter(x=\"sshf\", y=\"t2m\", marker=\".\", alpha=0.5, edgecolors=\"none\", **xrp)\n",
    "plt.ylim(ymin=286);  # exclude a few outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial problems\n",
    "\n",
    "If you are so inclined, pick something in here to work on for a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation\n",
    "\n",
    "Examine the autocorrelation plots of the different variables.\n",
    "\n",
    "You can use, e.g.:\n",
    "* [`pandas.plotting.autocorrelation_plot`](https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html)\n",
    "* [`statsmodels.graphics.tsaplots.plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)\n",
    "\n",
    "The autocorrelation will be different with daily data. Resample to daily time resolution using the [`.resample`](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.resample.html) method of our data set `ds` and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff (if necessary)\n",
    "...\n",
    "\n",
    "# make an autocorrelation plot or two\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest correlation between a pair of variables may be at different lags. We visualize this with cross-correlation plots.\n",
    "\n",
    "[`plt.xcorr`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xcorr.html) can be used to make such a plot.\n",
    "\n",
    "Compare the results for hourly data and for data resampled to daily time resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick variables\n",
    "...\n",
    "\n",
    "# plot xcorr\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare variables to Sun position\n",
    "\n",
    "Which have the strongest correlation?\n",
    "\n",
    "We can compute Sun position with [pvlib](https://pvlib-python.readthedocs.io/en/stable/). [Astropy](https://www.astropy.org/) could also be used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_pos = pvlib.solarposition.get_solarposition(ds.time.values, ds.latitude.values, ds.longitude.values)\n",
    "sun_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some of the Sun position variables to our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen_deg = sun_pos[\"zenith\"]\n",
    "zen = zen_deg.apply(np.deg2rad)\n",
    "ds[\"sza\"] = (\"time\", zen_deg, {\"long_name\": \"solar zenith angle\", \"units\": \"deg\"})\n",
    "ds[\"mu\"] = (\"time\", zen.apply(np.cos), {\"long_name\": \"cos(sza)\", \"units\": \"\"})\n",
    "ds[\"selev\"] = (\"time\", sun_pos[\"elevation\"], {\"long_name\": \"solar elevation angle\", \"units\": \"deg\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does near-surface air temperature compare to Sun angle? \n",
    "\n",
    "Note that we select data where the Sun is up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "day = ds.time.where(ds.selev > 10).dropna(\"time\")\n",
    "\n",
    "ds.sel(time=day).plot.scatter(x=\"sza\", y=\"t2m\", marker=\".\", alpha=0.5, edgecolors=\"none\", **xrp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation appears stronger if we first resample the hourly data to daily. Compare the linear fits, using, e.g., [OLS from statsmodels](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html) to compute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the strength of the linear fit, for hourly and daily data\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally explore the data, both Sun position and ERA5 surface variables\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow [this seaborn example](https://seaborn.pydata.org/examples/many_pairwise_correlations.html) to make a pairwise correlation heatmap. \n",
    "\n",
    "You can compute the correlation matrix by first converting the data set `ds` to a NumPy array (using `.to_array`) and then using, e.g., `np.corrcoef`, or first converting to a Pandas DataFrame (using `.to_dataframe`) and using the `.corr` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pairwise correlation heatmap\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SZA and maximum near-surface temperature\n",
    "\n",
    "It is well-known that the warmest temperatures generally lag the minimum solar zenith angle (SZA), on both seasonal and hourly (diurnal cycle) time scales.\n",
    "\n",
    "Find what that lag is.\n",
    "* seasonal: for each year find the lag between the yearly minimum SZA and maximum daily mean temperatue\n",
    "* diurnal: estimate time of min SZA and of max T for each day (possibly by interpolating) and examine the distribution of the offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal: for each year, calculate the two times and substract them\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diurnal\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove seasonal cycle\n",
    "\n",
    "This is often done in statistical analyses so that the seasonal cycle doesn't dominate the signal when looking for relationships.\n",
    "\n",
    "A common method is to represent the seasonal cycle using a number of harmonics, e.g., 10.\n",
    "\n",
    "Examine the estimated seasonal cycles of different variables and the time series with seasonal cycles removed, using the function provided below to calculate the seasonal cycles. If we have done a good job, we won't see periodic oscillations associated with the seasonal cycle in the anomaly time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate t_year (here hour-of-year, cf. day-of-year, which the .dt accessors provide) so we can group by it\n",
    "# I would like to know a better (more elegant) way to do this...\n",
    "t_year = ds.time - np.r_[[np.datetime64(f\"{x}\", \"D\") for x in ds.time.dt.year.values]]  # calc decDOY instead??\n",
    "ds[\"t_in_year\"] = (\"time\", t_year, {\"long_name\": \"time-in-year\"})\n",
    "t_year_leap = ds[\"t_in_year\"].where(ds.time.dt.year == 2016, drop=True).drop([\"latitude\", \"longitude\"], drop=True)\n",
    "# note: really we might want to remove leap days in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sc(da, n_harm):\n",
    "    \"Compute the mean seasonal cycle, given an xr.DataArray.\"\n",
    "    x = da.groupby(ds.t_in_year).mean().values  # group by hour in year\n",
    "    z = rfft(x)\n",
    "    z[n_harm:] = 0\n",
    "    return xr.DataArray(\n",
    "        name=f\"sc_{da.name}\", data=irfft(z), dims=\"doy\", coords=[t_year_leap.dt.days + t_year_leap.dt.seconds / (24*3600)],\n",
    "        attrs={\"long_name\": f\"mean seasonal cycle in {da.attrs['long_name']}\", \"units\": da.attrs[\"units\"]},\n",
    "    )\n",
    "\n",
    "vn = \"t2m\"  # select variable here\n",
    "n_harmonics = 2  # observe how changing the number impacts the results\n",
    "\n",
    "# Compute and plot seasonal cycle\n",
    "v = ds[vn]\n",
    "sc = compute_sc(v, n_harmonics)\n",
    "sc.plot(size=3, aspect=1.5); plt.xlabel(\"day-of-year\")\n",
    "\n",
    "# Substract seasonal cycle from the variable's time series\n",
    "year = v.time.dt.year  # also could use the shorthand `...groupby(\"time.year\")...`\n",
    "v_anom = v.groupby(year).map(lambda x: x - sc[:x.size].values)  # allow for leap years\n",
    "# Put the attrs back (I think they are lost because sc doesn't have them)\n",
    "v_anom.attrs.update(dict(long_name=f\"{v.attrs['long_name']} anomaly\", units=v.attrs[\"units\"]))\n",
    "\n",
    "# Plot hourly data and daily means\n",
    "def mu_sig(da):  # (estimated) mean and stdev\n",
    "    return f\"$\\mu={da.mean().values:.3g}$\\n$\\sigma={da.std().values:.3g}$\"\n",
    "v_anom.plot(size=3, aspect=2.5, lw=0.5); plt.title(mu_sig(v_anom), loc=\"right\")\n",
    "v_anom_daily = v_anom.resample(time=\"1D\").mean(keep_attrs=True)\n",
    "v_anom_daily.plot(size=3, aspect=2.5, lw=0.5); plt.title(mu_sig(v_anom_daily), loc=\"right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras\n",
    "\n",
    "### Map plot\n",
    "\n",
    "We plot data from ERA5 (not ERA5-Land) in a 20x20 degree box around the BEL location. The data are mean (over 1979--2019) monthly, thus, they show climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = xr.open_dataset(\"era5_bel-box_months_1979-2019.nc\")\n",
    "ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly see what some of the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3)); plt.imshow(ds2.t2m.sel(month=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot on map using [Cartopy](https://scitools.org.uk/cartopy/docs/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = ds2.latitude\n",
    "ds_subset = ds2.where((lat >= 35) & (lat <= 45), drop=True)  # cut off a bit\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "def plot_month(variable, imonth):\n",
    "    # select variable\n",
    "    da = ds_subset[variable]\n",
    "    \n",
    "    # same contour levels for all months. change `40` to get a different number of levels\n",
    "    l, h = np.floor(da.min().values), np.ceil(da.max().values); step = np.ceil((h-l)/40)\n",
    "    levels = np.arange(l, h+step, step)\n",
    "    \n",
    "    # erase and re-setup\n",
    "    fig.clear()\n",
    "    ax = plt.axes(projection=ccrs.Mercator())\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.STATES)  # only US, requires sufficiently recent Cartopy\n",
    "    gl = ax.gridlines(draw_labels=True)\n",
    "    #gl.xlabels_top = False; gl.ylabels_right = False  # now deprecated, but switch to this one if the following doesn't work\n",
    "    gl.top_labels = False; gl.right_labels = False  # preferred syntax\n",
    "    \n",
    "    # plot selected month\n",
    "    data = da.sel(month=imonth)\n",
    "    data.plot.contourf(x=\"longitude\", y=\"latitude\", levels=levels, ax=ax, transform=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"{ax.get_title()} ({calendar.month_name[imonth]})\")\n",
    "\n",
    "    \n",
    "interact(plot_month, variable=Dropdown(options=list(ds2.keys())), imonth=(1, 12, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "General references:\n",
    "\n",
    "* <https://xarray.pydata.org/en/stable/>\n",
    "  - http://xarray.pydata.org/en/stable/related-projects.html#related-projects\n",
    "* <https://pandas.pydata.org/docs/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "297px",
    "left": "22px",
    "top": "111.14px",
    "width": "272.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
